## Today I Learned
### 웹크롤링
```
# 우클릭 >copy> xpath copy
# 자바스크립트 써도 되고 xpath써도 됨
# 동적인 방식은 정적인 방식을 포함(근데 동적인건 느림)
```
- 정적 웹크롤링 순서
1. 필요한 라이브러리 import
>
2. User-Agent 설정
`headers = {'User-Agent': '유저에이전트입력'}`
>
3. 빈 리스트 생성하여 데이터 저장 준비
`someList = []`
>
4. 페이지별로 데이터 수집
```
# URL 설정
url = f"https://@#@@#@#@#

# HTML 가져오기
response = requests.get(url, headers=headers)
response.encoding = 'euc-kr' # 한글 인코딩

# BeautifulSoup으로 HTML 파싱
soup = BeautifulSoup(response.text, 'html.parser')

# 데이터가 있는 행 찾기(e.g.)
tag_trs = soup.find_all('tr', attrs={"onmouseover": "mouseOver(this)"})

# 각 행에서 데이터 추출(e.g.)
for tr in tag_trs:
    tds = tr.find_all("td")  # tr에 있는 td 모두 찾기
    if led(tds) != 7:
        continue  # 데이터 검증

# td에 있는 필요 요소를 알맞게 추출
.text.strip().replace(',', '')

# 추출한 데이터를 리스트에 추가
.append()

# 크롤링 간격 설정
time.sleep()

# 데이터프레임 생성
df = pd.DataFrame(someList)
````
