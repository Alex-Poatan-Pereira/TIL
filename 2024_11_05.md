## Today I Learned
### AI활용
- GPT를 이용해 문장 파악하기
`model = Transformer(d_model = 512 , nhead = 8 , num_encoder_layers = 6, num_decoder_layers = 6)`
d_model 단어의 임베딩 차원 수 , nhead 멀티헤드어텐션의 헤드 수
>
`optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)`
파라미터가 많고 깊고 복잡한 경우 lr(러닝레이트)를 작게 설정. 큰 lr을 설정하는 경우 학습이 불안정해 질 수 있다.
>
BERT모델의 경우 사용자가 직접 파인튜닝을 해줘야 한다(목적에 따라 적절히 학습된 모델이지 완전한 모델이 아님
>
Word2vec 주변 단어와의 관계를 봄.
Word2Vec은 입력단위를 단어로 줘야 함.
`model2 = Word2Vec(sentences = processed, vector_size = 5, window = 5, min_count = 1, sg = 0)`
vector_size 각각의 단어를 몇차원에 고정시킬것인가. window 주변 단어와의 관계를 얼마나 넓게 볼 것인가. min_count 최소 몇번 등장해야 해당 단어를 임베딩할 것인가(여기서는 1번 미만으로 등장하는 단어는 학습하지 않는다. sg Word2Vec이 어떤 알고리즘을 통해 학습할 것인가)
>
`sim = 1 - cosine(dog,cat)`
cosine유사도를 이용해서 두 벡터간의 유사도를 확인
>
```
with torch.no_grad():  #연산속도를 올리고 메모리 사용량을 줄이기 위해 학습단계에서 필요한 오토그레드를 꺼줌
    output1 = model3(**input1)
    output2 = model3(**input2)
```
>
`embedding1 = output1.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()`
1차원으로 만듦(cosine 계산을 위해서)
---
- BERT
`dataset = load_dataset("imdb")`
imdb 인터넷,영화 데이터베이스에서 수집된 영화의 리뷰텍스트와 그에 대한 감정레이블이 포함된 데이터셋(0부정, 1긍정)
>
`tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")`
감정분석, 기타 자연어처리작업에서 사용하는 일반적인 모델. 사전학습모델. 영어텍스트에 좋음(대소문자구분X).문장길이 최대 512토큰. 파인튜닝 필요
>
```
def tokenize_function(examples):
    return tokenizer(examples["text"],padding="max_length", truncation=True)
#example["text"]는 imdb 데이터셋에서 리뷰부분을 가져옴
#tokenizer는 BERT모델이 이해할 수 있는 형태인 토큰으로 변환(텍스트>토큰)
#padding 모든 텍스트를 쵀대 길이로 패딩(BERT에서 최대는 512토큰이라서 패딩된 토큰은 무시되고, 모든 입력이 동일한 길이를 갖도록 한다)
#truncation 텍스트의 길이가 최대길이를 초과한 경우 초과된 부분을 잘라냄
```
>
`test_dataset = test_dataset.map(tokenize_function, batched=True)``
batched는 batch단위로 함수를 적용해서 여러샘플을 한번에 처리(속도향상, 메모리최적화)
>
```
test_dataset.set_format(type="torch", columns=['input_ids', 'attention_mask', 'label'])
#set_format 데이터셋을 특정형태로 변경(type="torch")
#columns은 BERT모델에 필요한 데이터셋만 선택
```
>
```
for batch in torch.utils.data.DataLoader(test_dataset, batch_size=8):  #test_dataset 평가에 사용할 데이터셋, 배치사이즈 결정
    with torch.no_grad():                                             #해당 블록에 실행된 코드는 그래디언트를 계산하지 않는다(추론을 하는데 사용)(메모리,연산속도 이점이 있다)
        outputs = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])
    logits = outputs.logits
    preds = np.argmax(logits.numpy(), axis=1)
    all_preds.extend(preds)
    all_labels.extend(batch['label'].numpy())
```
>
```
train_dataset = dataset['train'].shuffle(seed=42).select(range(1000))  # 1000개 샘플로 축소
test_dataset = dataset['test'].shuffle(seed=42).select(range(500))  # 500개 샘플로 축소
```
>
```
# 훈련 인자 설정
training_args = TrainingArguments(   #모델 훈련 시 필요한 설정등을 정의
    output_dir='./results',         #훈련중 생성된 모델 파일 및 로그를 저장할 디렉토리
    num_train_epochs=3,             #훈련 에폭
    per_device_train_batch_size=8,  
    per_device_eval_batch_size=8,
    evaluation_strategy="epoch",  #평가전략 : 에폭단위(에폭이 끝날때마다 평가 진행)
    save_steps=10_000,            #몇 스텝마다 저장할지
    save_total_limit=2,           #저장할 최대 체크포인트 옵션
)

# 트레이너 설정(모델 훈련, 평가, 예측을 간단하게 수행)
trainer = Trainer(
    model=model,                   #훈련시킬 모델
    args=training_args,            #학습을 위한 설정 값
    train_dataset=train_dataset,   #트레인 데이터셋
    eval_dataset=test_dataset,     #테스트 데이터셋
)
```
>
```
# 평가 지표 함수 정의
def compute_metrics(p):
    preds = np.argmax(p.predictions, axis=1)  # 예측된 클래스
    labels = p.label_ids  # 실제 레이블
    acc = accuracy_score(labels, preds)  # 정확도 계산
    return {'accuracy': acc}

# 이미 훈련된 트레이너에 compute_metrics를 추가하여 평가(모델 평가 시 사용할 함수)
trainer.compute_metrics = compute_metrics
```
---
- OpenAI
`app = FastAPI()`
#API서버 초기화. 모든 API요청이 이 인스턴스를 통해 처리됨
>
```
# (대화를 하기 위해서)대화 내역을 저장할 리스트 초기화
messages = [system_message]

@app.get("/", response_class=HTMLResponse)
async def get_chat_page(request: Request):
    """채팅 페이지 렌더링"""  #경로 지정. 대화페이지를 html로 반환. conversation_history 리스트에 저장된 대화내역을 템플릿으로 랜더링
    conversation_history = [msg for msg in messages if msg["role"] != "system"]
    return templates.TemplateResponse("index.html", {"request": request, "conversation_history": conversation_history})
```
---
- GPT와 대화하기
```
client = OpenAI()

completion = client.chat.completions.create(   #completion 결과저장
  model="gpt-4o",
  messages=[
    {"role": "system", "content": "너는 환영 인사를 하는 인공지능이야, 농담을 넣어 재미있게해줘"},  #role 역할부여. system이라고 전달되면 시스템 전반에 영향을 미침. system이라는 역할에 content라는 명령어를 준다
    {"role": "user", "content": "안녕?"}  #user 유저의 입장에서 명령어 "안녕?" 전달
  ]
)
```

>
```
message = [system_message]

#대화를 위한 반복문
while True:
    user_input = input("사용자 전달")
    if user_input == "exit" :  #종료지점 설정해줘야 함
        print("대답: 감사합니다.")
        break

    message.append({"role":"user","content":user_input  #append() 덧붙이기
    completion = client.chat.completions.create(
        model = "gpt-4o",
        messages = messages
    )

    reply = completion.choices[0].message.content
    print("대답: " = reply)
    messages.append({"role":"assistant","content":reply}) #assistant에 대답을 넣어주면 gpt가 대화를 인지할 수 있게 됨


#시스템 : 나에게 내리는 지침
#유저 : 나한테 전달해 온 입력
#어플라이 : 입력에 대해 제공한 출력

```
>
`import dotenv import load_dotenv`
env파일로 api키 불러오기
>
```
data = {
    "text": text,
    "model_id": "eleven_multilingual_v2",
    "voice_settings": {
        "stability": 0.3,       #음정 변화 없이 안정적으로 읽을것인가(값이 낮아지면 변동이 심함. 0.3이하는 추천하지 않음)
        "similarity_boost": 1,  #녹음된 목소리와의 유사도
        "style": 1,             #특유의 억양 반영 정도
        "use_speaker_boost": True
    }
}
```
>
```
if response.status_code == 200:  #HTTP 상태코드(API요청이 성공했을 시 200이 나타남)
    audio_content = b""        #오디오 단위는 바이트단위(바이트 문자열 초기화 해줌)
    for chunk in response.iter_content(chunk_size=1024):  #chunk(청크) 단위로 읽어온 다음 응답데이터를 처리(큰 파일을 효율적으로 처리하는 방법)
        if chunk:
            audio_content += chunk

    segment = AudioSegment.from_mp3(io.BytesIO(audio_content))  #byte데이터>>메모리파일>>mp3파일
    segment.export(output_filename, format="mp3")      #변환된 오디오의 이름, 형식을 저장
    print(f"Success! Wrote audio to {output_filename}")

    # 오디오를 재생합니다.
    play(segment)
else:
    print(f"Failed to save file: {response.status_code}")
```
---
- YOLO
cv2 이미지, 다양한 시각처리에 유용
.
```
result = results[0]
#YOLO는 하나의 이미지가 들어왔을때 그리드로 분리. 따라서 이 results는 그냥 출력하면 이미지가 아닌 다른 결과를 출력함
```
