## Today I Learned
xgboost 모델 생성
xgb_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)
n_estimators 트리의 개수, learning_rate 학습 단계별로 가중치를 얼만큼 사용할지, 또는 이전의 결과를 얼마나 반영할건지 결정
max_depth 트리의 최대 깊이

모델 학습
xgb_model.fit(X_train_scaled, y_train)

예측
y_pred_xgb = xgb_model.predict(X_test_scaled)

평가
mse_xgb = mean_squared_error(y_test, y_pred_xgb)
print(f'XGBoost 모델의 MSE: {mse_xgb}')
mse값이 0에 가까울수록 예측한 값이 실제 값과 비슷함