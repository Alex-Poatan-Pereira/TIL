## Today I Learned
### 인공 신경망(Artificial Neural Network, ANN)
생물학적 신경망을 모방. 입력층(Input Layer), 은닉층(Hidden Layer), 출력층(Output Layer)로 구성되며 각 층은 뉴런으로 이루어짐
```
동작방식
1. 순전파(Forward Propagation)
입력 데이터를 통해 각 층의 뉴런이 활성화되고 최종 출력값을 계산.
각 뉴런은 입력 값에 가중치를 곱하고 바이어스를 더한 후 활성화 함수를 통해 값을 결정
2. 손실계산(Loss Calculation)
예측 값과 실제 값의 차이를 손실함수(Loss Function)로 계산
3. 역전파(Backpropagation)
손실 함수의 기울기를 출력층에서 입력층 방향으로 계산하고 이를 바탕으로 가중치를 업데이트
```
>
### 합성곱 신경망(Convolutional Neural Network, CNN)
이미지와 같은 2차원 데이터의 특징을 효과적으로 추출하기 위해 설계된 신경망
합성곱 층(Convolutional Layer) : 입력 이미지에 필터를 적용하여 특징 맵을 생성. 이미지의 국소적인 패턴을 학습
풀링 층(Pooling Layer) : 특징 맵의 크기를 줄이고, 중요한 특징을 추출
완전 연결 층(Fully Connected Layer) : 추출된 특징을 바탕으로 최종 예측을 수행
`Max Polling : 필터 크기 내에서 최대 값을 선택. 중요한 특징 강조, 불필요한 정보 제거`
`Average Pooling : 필터 크기 내에서 평균 값을 계산. 특징맵의 크기를 줄이면서, 정보의 손실 최소화`
`플래튼 층(Flatten Layer) : 2차원 특징 맵을 1차원 벡터로 변환. 완전 연결 층에 입력으로 사용하기 위해 필요`
>
### 순환 신경망(Recurrent Neural Network, RNN)
시계열 데이터나 순차적인 데이터를 처리하기 위해 설계된 신경망
시퀀스의 각 시간 단계에서 동일한 가중치를 공유하여 시퀀스의 패턴을 학습
```
LSTM(Long Short-Term Memory)
셀 상태(cell state)와 게이트(gate) 구조를 도입하여 장기 의존성을 효과적으로 학습
입력 게이트(input gate), 출력게이트(output gate), 망각게이트(forget gate) 사용
```
```
GRU(Gated Recurrent Unit)
셀 상태 대신 은닉 상태(hidden state)만을 사용하여 구조를 단순화
업데이트 게이트(update gate), 리셋 게이트(reset gate) 사용
```